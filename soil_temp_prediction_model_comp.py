# -*- coding: utf-8 -*-
"""5460-Trial1-NovPB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/154FYOk4FbEG_iIItQ0hEXuC7JQyAUGoU
"""

!pip install xarray
!pip install netcdf4

import pandas as pd
import time
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.optimizers import Adam

# Load and preprocess data
xrds = xr.open_dataset("data0.nc")
stl1 = (xrds['stl1'].values - 273) / 50  # Normalize
lat_idx, lon_idx = 4, 4
stl1_seq = stl1[:, lat_idx, lon_idx]

scaler = MinMaxScaler()
stl1_scaled = scaler.fit_transform(stl1_seq.reshape(-1, 1)).flatten()

# Prepare data
seq_len = 12
x = np.array([stl1_scaled[i:i + seq_len] for i in range(len(stl1_scaled) - seq_len)])
y = stl1_scaled[seq_len:]
x = x.reshape(-1, seq_len, 1)

# Train-test split
train_size = int(0.8 * len(x))
x_train, x_test = x[:train_size], x[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Model
model = Sequential([
    LSTM(64, activation='relu', input_shape=(seq_len, 1), return_sequences=True),
    LSTM(32, activation='relu'),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(x_train, y_train, epochs=7, batch_size=16, validation_data=(x_test, y_test), verbose=0)

# Predict
y_pred = scaler.inverse_transform(model.predict(x_test)).flatten()
y_true = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

# Plot
plt.plot(y_true, label='True stl1', color='blue', linewidth=2)
plt.plot(y_pred, label='Predicted stl1', color='red', linestyle='--')
plt.title('True vs Predicted stl1')
plt.legend()
plt.show()

# Metrics
print(f"MAE: {mean_absolute_error(y_true, y_pred):.4f}")
print(f"MSE: {mean_squared_error(y_true, y_pred):.4f}")
print(f"R2: {r2_score(y_true, y_pred):.4f}")

import xarray as xr
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load and preprocess data
xrds0, xrds1 = xr.open_dataset("data0.nc"), xr.open_dataset("data1.nc")
stl1 = (xrds0['stl1'].values - 273) / 50
t2m = (xrds1['t2m'].values - 273) / 50
lat_idx, lon_idx = 4, 4
diff = stl1[:, lat_idx, lon_idx] - t2m[:, lat_idx, lon_idx]

# Normalize
scaler = MinMaxScaler()
diff_scaled = scaler.fit_transform(diff.reshape(-1, 1)).flatten()

# Prepare data
seq_len = 12
x = np.array([diff_scaled[i:i + seq_len] for i in range(len(diff_scaled) - seq_len)])
y = diff_scaled[seq_len:]
x = x.reshape(-1, seq_len, 1)

# Train-test split
split = int(0.8 * len(x))
x_train, x_test, y_train, y_test = x[:split], x[split:], y[:split], y[split:]

# Model
model = Sequential([LSTM(64, activation='relu', return_sequences=True, input_shape=(seq_len, 1)),
                    LSTM(32, activation='relu'), Dense(1)])
model.compile(optimizer='adam', loss='mse')
model.fit(x_train, y_train, epochs=7, batch_size=16, verbose=0, validation_data=(x_test, y_test))

# Predict
pred_diff = scaler.inverse_transform(model.predict(x_test)).flatten()
true_diff = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
t2m_test = t2m[-len(pred_diff):, lat_idx, lon_idx]
predicted_stl1 = t2m_test + pred_diff
true_stl1 = stl1[-len(pred_diff):, lat_idx, lon_idx]

# Plot
plt.figure(figsize=(12, 5))
plt.plot(true_stl1, label='True stl1', color='blue')
plt.plot(predicted_stl1, label='Predicted stl1', color='red', linestyle='--')
plt.plot(t2m_test, label='t2m (Reference)', color='green', linestyle=':')
plt.title('True vs Predicted stl1 with t2m')
plt.legend()
plt.show()

# Metrics
print(f"MAE: {mean_absolute_error(true_stl1, predicted_stl1):.4f}")
print(f"MSE: {mean_squared_error(true_stl1, predicted_stl1):.4f}")
print(f"R2: {r2_score(true_stl1, predicted_stl1):.4f}")

import xarray as xr
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error

# Load datasets
xrds0, xrds1 = xr.open_dataset("data0.nc"), xr.open_dataset("data1.nc")
stl1 = (xrds0['stl1'].values - 273) / 50
t2m = (xrds1['t2m'].values - 273) / 50
lat, lon = xrds0['latitude'].values, xrds0['longitude'].values
diff = stl1 - t2m

# Features: past 3 time steps + time of day
def prepare_data(target, time_of_day, seq_len=3):
    x, y = [], []
    for i in range(seq_len, len(target) - 1):
        x.append(np.append(target[i-seq_len:i].flatten(), time_of_day[i]))
        y.append(target[i + 1])
    return np.array(x), np.array(y).reshape(len(y), -1)

# Time-of-day
time_steps = stl1.shape[0]
time_of_day = np.tile(np.linspace(0, 1, 24), time_steps // 24 + 1)[:time_steps]

# Data preparation
x_temp, y_temp = prepare_data(stl1, time_of_day)
x_diff, y_diff = prepare_data(diff, time_of_day)

# Split train/test
split = int(0.8 * len(x_temp))
datasets = [(x_temp, y_temp), (x_diff, y_diff)]
results = []

# Model training and evaluation
for x, y in datasets:
    x_train, x_test, y_train, y_test = x[:split], x[split:], y[:split], y[split:]
    model = Sequential([Dense(256, activation='relu', input_shape=(x.shape[1],)),
                        Dense(128, activation='relu'), Dense(y.shape[1])])
    model.compile(optimizer=Adam(0.001), loss='mse')
    model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=0)
    y_pred = model.predict(x_test).reshape(-1, stl1.shape[1], stl1.shape[2])
    y_true = y_test.reshape(-1, stl1.shape[1], stl1.shape[2])
    results.append((y_pred, y_true, mean_absolute_error(y_true.flatten(), y_pred.flatten())))

# Reconstruct stl1 for the difference model
stl1_reconstructed = t2m[-len(results[1][0]):] + results[1][0]

# Plot results
fig, axes = plt.subplots(2, 3, figsize=(9, 6))
titles = ["True Temperature", "Predicted (Temp Learning)", "Predicted (Difference Learning)"]
for i, (pred, ax_row) in enumerate(zip([results[0][0], stl1_reconstructed], axes)):
    ax_row[0].contourf(lon, lat, results[0][1][0], cmap='viridis'); ax_row[0].set_title(titles[0])
    ax_row[1].contourf(lon, lat, results[0][0][0], cmap='viridis'); ax_row[1].set_title(titles[1])
    ax_row[2].contourf(lon, lat, pred[0], cmap='viridis'); ax_row[2].set_title(titles[2])

plt.tight_layout()
plt.show()
print(f"MAE (Temperature Learning): {results[0][2]:.4f}")
print(f"MAE (Difference Learning): {results[1][2]:.4f}")

def train_and_evaluate_model(x_train, y_train, x_test, y_test, epochs, batch_size=32):
    """Train model with specified epochs and return metrics"""
    model = Sequential([
        Dense(256, activation='relu', input_shape=(x_train.shape[1],)),
        Dense(128, activation='relu'),
        Dense(y_train.shape[1])
    ])

    model.compile(optimizer=Adam(0.001), loss='mse')

    # Add early stopping
    early_stopping = EarlyStopping(
        monitor='loss',
        patience=5,
        restore_best_weights=True
    )

    # Time the training
    start_time = time.time()
    history = model.fit(
        x_train, y_train,
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[early_stopping],
        verbose=0
    )
    training_time = time.time() - start_time

    # Evaluate
    y_pred = model.predict(x_test).reshape(-1, stl1.shape[1], stl1.shape[2])
    y_true = y_test.reshape(-1, stl1.shape[1], stl1.shape[2])
    mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())

    return {
        'mae': mae,
        'training_time': training_time,
        'final_loss': history.history['loss'][-1],
        'epochs_completed': len(history.history['loss']),
        'history': history
    }

def run_epoch_comparison(epochs_list, datasets):
    """Run comparison across different epoch counts"""
    results = []

    for epochs in epochs_list:
        print(f"\nTesting with {epochs} epochs...")
        epoch_results = {}

        for i, (x, y) in enumerate(datasets):
            model_type = "Temperature" if i == 0 else "Difference"
            split = int(0.8 * len(x))
            x_train, x_test = x[:split], x[split:]
            y_train, y_test = y[:split], y[split:]

            metrics = train_and_evaluate_model(x_train, y_train, x_test, y_test, epochs)

            epoch_results.update({
                'epochs': epochs,
                f'{model_type}_MAE': metrics['mae'],
                f'{model_type}_Time': metrics['training_time'],
                f'{model_type}_FinalLoss': metrics['final_loss'],
                f'{model_type}_EpochsCompleted': metrics['epochs_completed']
            })

        results.append(epoch_results)

    return pd.DataFrame(results)

# Load datasets
xrds0, xrds1 = xr.open_dataset("data_0.nc"), xr.open_dataset("data_1.nc")
stl1 = (xrds0['stl1'].values - 273) / 50
t2m = (xrds1['t2m'].values - 273) / 50
lat, lon = xrds0['latitude'].values, xrds0['longitude'].values
diff = stl1 - t2m

# Features: past 3 time steps + time of day
def prepare_data(target, time_of_day, seq_len=3):
    x, y = [], []
    for i in range(seq_len, len(target) - 1):
        x.append(np.append(target[i-seq_len:i].flatten(), time_of_day[i]))
        y.append(target[i + 1])
    return np.array(x), np.array(y).reshape(len(y), -1)

# Time-of-day
time_steps = stl1.shape[0]
time_of_day = np.tile(np.linspace(0, 1, 24), time_steps // 24 + 1)[:time_steps]

# Data preparation
x_temp, y_temp = prepare_data(stl1, time_of_day)
x_diff, y_diff = prepare_data(diff, time_of_day)

epochs_to_test = [10, 20, 30, 40, 50]
datasets = [(x_temp, y_temp), (x_diff, y_diff)]
results_df = run_epoch_comparison(epochs_to_test, datasets)

results_df

# prompt: results df with only epochs, Temperature_MAE, and Difference_MAE

results_df[['epochs', 'Temperature_MAE', 'Difference_MAE']]

